CUDA_VISIBLE_DEVICES=0 python src/train_bash.py 
\--stage sft 
\--do_train True 
\--model_name_or_path /root/model/chatglm3-6b 
\--finetuning_type lora 
\--template chatglm3 
\--dataset_dir data 
\--dataset self_cognition 
\--cutoff_len1024\--learning_rate 5e-05 
\--num_train_epochs50.0
\--max_samples100000
\--per_device_train_batch_size2
\--gradient_accumulation_steps8
\--lr_scheduler_type cosine 
\--max_grad_norm1.0
\--logging_steps5
\--save_steps100
\--warmup_steps0
\--optim adamw_torch 
\--report_to none 
\--output_dir saves/ChatGLM3-6B-Chat/lora/train_2024-04-19-12-36-29 
\--fp16 True 
\--lora_rank8
\--lora_alpha16
\--lora_dropout0.1
\--lora_target query_key_value 
\--plot_loss True 